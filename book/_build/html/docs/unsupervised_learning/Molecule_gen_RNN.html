
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Exercise: Molecule Generation with an RNN &#8212; Machine Learning for Scientists</title>
    
  <link rel="stylesheet" href="../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Exercise: Anomaly Detection" href="Anomaly_Detection_RNN_AE_VAE.html" />
    <link rel="prev" title="Exercise: Denoising with Restricted Boltzmann Machines" href="Denoising.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/cluster.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Machine Learning for Scientists</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Lecture
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../structuring_data/ml_without_neural_network.html">
   Structuring Data without Neural Networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../structuring_data/ml_without_neural_network-1.html">
     Principle Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../structuring_data/ml_without_neural_network-2.html">
     Kernel PCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../structuring_data/ml_without_neural_network-3.html">
     t-SNE as a Nonlinear Visualization Technique
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../structuring_data/ml_without_neural_network-4.html">
     Clustering Algorithms: the example of
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -means
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../structuring_data/pca.html">
     Exercise: Principle Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../structuring_data/Dimensionality_reduction.html">
     Exercise: Dimensionality Reduction
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../supervised_learning_wo_NNs/ml_supervised_wo_NNs.html">
   Supervised Learning without Neural Networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_wo_NNs/ml_supervised_wo_NNs-1.html">
     Linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_wo_NNs/ml_supervised_wo_NNs-2.html">
     Binary Classification and Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_wo_NNs/ml_supervised_wo_NNs-3.html">
     More than two classes: logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_wo_NNs/Linear-regression.html">
     Exercise: Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_wo_NNs/Classification.html">
     Exercise: Classification without Neural Networks
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../supervised_learning_w_NNs/ml_supervised_w_NNs.html">
   Supervised Learning with Neural Networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_w_NNs/Classification-2.html">
     Exercise: Dense Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_w_NNs/NN-opt-reg.html">
     Exercise: Machine Learning Optimizers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_w_NNs/NN-opt-reg.html#exercise-learning-rate-scheduling">
     Exercise: Learning Rate Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_w_NNs/NN-opt-reg.html#exercise-regularizing-neural-networks">
     Exercise: Regularizing Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_w_NNs/CNNs.html">
     Exercise: Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_w_NNs/exoplanets_RNN_CNN.html">
     Exercise: Discovery of Exoplanets with RNNs and CNNs
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="ml_unsupervised.html">
   Unsupervised Learning
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="ml_unsupervised-1.html">
     Restricted Boltzmann Machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ml_unsupervised-2.html">
     Training an RNN without Supervision
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ml_unsupervised-3.html">
     Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ml_unsupervised-4.html">
     Generative Adversarial Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Denoising.html">
     Exercise: Denoising with Restricted Boltzmann Machines
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Exercise: Molecule Generation with an RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Anomaly_Detection_RNN_AE_VAE.html">
     Exercise: Anomaly Detection
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../interpretability/ml_interpretability.html">
   Interpretability of Neural Networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../interpretability/ml_interpretability-1.html">
     Dreaming and the Problem of Extrapolation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../interpretability/ml_interpretability-2.html">
     Adversarial Attacks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../interpretability/ml_interpretability-3.html">
     Interpreting Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../interpretability/Transfer-learning-attacks.html">
     Exercise: Transfer Learning and Adversarial Attacks
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../reinforcement_learning/ml_reinforcement-learning.html">
   Reinforcement Learning
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../reinforcement_learning/ml_reinforcement-learning-1.html">
     Exploration versus Exploitation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reinforcement_learning/ml_reinforcement-learning-2.html">
     Finite Markov Decision Process
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reinforcement_learning/ml_reinforcement-learning-3.html">
     Policies and Value Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reinforcement_learning/ml_reinforcement-learning-4.html">
     Temporal-difference Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reinforcement_learning/ml_reinforcement-learning-5.html">
     Function Approximation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../conclusion/ml_conclusion.html">
   Concluding Remarks
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  About us
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../about_us.html">
   Who we are
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/docs/unsupervised_learning/Molecule_gen_RNN.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preparations">
   Preparations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-the-rnn">
   Training the RNN
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interlude-how-to-store-and-load-keras-models">
   Interlude: How to store and load keras models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation">
   Evaluation
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">chain</span>
<span class="kn">from</span> <span class="nn">rdkit</span> <span class="kn">import</span> <span class="n">Chem</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span>
</pre></div>
</div>
<div class="section" id="exercise-molecule-generation-with-an-rnn">
<h1>Exercise: Molecule Generation with an RNN<a class="headerlink" href="#exercise-molecule-generation-with-an-rnn" title="Permalink to this headline">¶</a></h1>
<p>In this exercise sheet we will be generating molecules using the simplified molecular-input line-entry system (SMILES). This system allows to describe the structure of chemical species in the form of a line notation, making it suited for a machine learning approach with recurrent neural networks. The data can be obtained from <a class="footnote-reference brackets" href="#id3" id="id1">3</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the data</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s1">&#39;smiles.csv&#39;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;U&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>“train_data” contains strings of characters that encode molecules, which you can visualize with the rdkit package <a class="footnote-reference brackets" href="#id4" id="id2">4</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>array([&#39;CC1C2CCC(C2)C1CN(CCO)C(=O)c1ccc(Cl)cc1&#39;,
       &#39;COc1ccc(-c2cc(=O)c3c(O)c(OC)c(OC)cc3o2)cc1O&#39;,
       &#39;CCOC(=O)c1ncn2c1CN(C)C(=O)c1cc(F)ccc1-2&#39;,
       &#39;Clc1ccccc1-c1nc(-c2ccncc2)no1&#39;,
       &#39;CC(C)(Oc1ccc(Cl)cc1)C(=O)OCc1cccc(CO)n1&#39;], dtype=&#39;&lt;U53&#39;)
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note that this will only work if you installed the rdkit package!</span>
<span class="n">Chem</span><span class="o">.</span><span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p><img alt="png" src="../../_images/mg_output_6_0.png" /></p>
<div class="section" id="preparations">
<h2>Preparations<a class="headerlink" href="#preparations" title="Permalink to this headline">¶</a></h2>
<p>In order to make the data usable for a neural network we have to generate a mapping from characters to integers and vice versa.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># creating mapping for each char to integer, also mapping for the E (end) is manually inserted into the dictionaries.</span>
<span class="n">unique_chars</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">OrderedDict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="n">train_data</span><span class="p">))))</span>
<span class="c1"># maps each unique character as int</span>
<span class="n">char_to_int</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">c</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_chars</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># int to char dictionary</span>
<span class="n">int_to_char</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_chars</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">char_to_int</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;(&#39;: 0,
 &#39;)&#39;: 1,
 &#39;-&#39;: 2,
 &#39;1&#39;: 3,
 &#39;2&#39;: 4,
 &#39;3&#39;: 5,
 &#39;4&#39;: 6,
 &#39;5&#39;: 7,
 &#39;6&#39;: 8,
 &#39;=&#39;: 9,
 &#39;B&#39;: 10,
 &#39;C&#39;: 11,
 &#39;F&#39;: 12,
 &#39;H&#39;: 13,
 &#39;N&#39;: 14,
 &#39;O&#39;: 15,
 &#39;S&#39;: 16,
 &#39;[&#39;: 17,
 &#39;]&#39;: 18,
 &#39;c&#39;: 19,
 &#39;l&#39;: 20,
 &#39;n&#39;: 21,
 &#39;o&#39;: 22,
 &#39;r&#39;: 23,
 &#39;s&#39;: 24}
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">int_to_char</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>{0: &#39;(&#39;,
 1: &#39;)&#39;,
 2: &#39;-&#39;,
 3: &#39;1&#39;,
 4: &#39;2&#39;,
 5: &#39;3&#39;,
 6: &#39;4&#39;,
 7: &#39;5&#39;,
 8: &#39;6&#39;,
 9: &#39;=&#39;,
 10: &#39;B&#39;,
 11: &#39;C&#39;,
 12: &#39;F&#39;,
 13: &#39;H&#39;,
 14: &#39;N&#39;,
 15: &#39;O&#39;,
 16: &#39;S&#39;,
 17: &#39;[&#39;,
 18: &#39;]&#39;,
 19: &#39;c&#39;,
 20: &#39;l&#39;,
 21: &#39;n&#39;,
 22: &#39;o&#39;,
 23: &#39;r&#39;,
 24: &#39;s&#39;}
</pre></div>
</div>
<p>The dataset contains sequences of varying length, which usually isn’t a problem when using a RNN. In the next exercise however we want to use batch training, which requires all sequences in the batch to be of equal length. We therefore have to append each sequence with an appropriate number of end characters ”E” to ensure an equal length. Before we do that we add “E” to our dictionary.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># add stop letter to dictionary</span>
<span class="n">char_to_int</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;E&quot;</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">char_to_int</span><span class="p">)})</span>
<span class="n">int_to_char</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="nb">len</span><span class="p">(</span><span class="n">int_to_char</span><span class="p">)</span> <span class="p">:</span> <span class="s2">&quot;E&quot;</span><span class="p">})</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># how many unique characters do we have?</span>
<span class="n">mapping_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">char_to_int</span><span class="p">)</span>
<span class="n">reverse_mapping_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">int_to_char</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Size of the character to integer dictionary is: &quot;</span><span class="p">,</span> <span class="n">mapping_size</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Size of the integer to character dictionary is: &quot;</span><span class="p">,</span> <span class="n">reverse_mapping_size</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Size of the character to integer dictionary is:  26
Size of the integer to character dictionary is:  26
</pre></div>
</div>
<p>We want to train the RNN in a many-to-many approach, in which we always predict the respective next character in the sequence. The resulting dimension of both X and Y array should be (number of training samples, length of sequences, length of dictionary). The last dimension is used as a one-hot-encoding of the respective character. We create this encoding by iterating over the dataset, taking all characters of each sequence except for the last one as part of X, and all characters of each sequence except for the first one as part of Y.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate the datasets</span>
<span class="k">def</span> <span class="nf">gen_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">int_to_char</span><span class="p">,</span> <span class="n">char_to_int</span><span class="p">,</span> <span class="n">embed</span><span class="p">):</span>
    
    <span class="n">one_hot</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">embed</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">char_to_int</span><span class="p">)),</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">smile</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="c1">#encode the chars</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span><span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">smile</span><span class="p">):</span>
            <span class="n">one_hot</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">char_to_int</span><span class="p">[</span><span class="n">c</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="c1">#Encode endchar</span>
        <span class="n">one_hot</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">smile</span><span class="p">):,</span><span class="n">char_to_int</span><span class="p">[</span><span class="s2">&quot;E&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="c1">#Return two, one for input and the other for output</span>
    <span class="k">return</span> <span class="n">one_hot</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:],</span> <span class="n">one_hot</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:,:]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># get longest sequence</span>
<span class="n">embed</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span> <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">train_data</span><span class="p">])</span>

<span class="c1"># Get datasets</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">gen_data</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">int_to_char</span><span class="p">,</span> <span class="n">char_to_int</span><span class="p">,</span> <span class="n">embed</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="training-the-rnn">
<h2>Training the RNN<a class="headerlink" href="#training-the-rnn" title="Permalink to this headline">¶</a></h2>
<p>Now we want to build and train the neural network. In order to account for different sequence lengths in the evaluation, we specify the first input dimension to the LSTM as ”None”.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;CREATING THE LSTM MODEL &quot;&quot;&quot;</span>

<span class="c1"># Create the model (simple 2 layer LSTM)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="n">return_sequences</span> <span class="o">=</span> <span class="kc">True</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">return_sequences</span> <span class="o">=</span> <span class="kc">True</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, None, 256)         289792    
_________________________________________________________________
dropout (Dropout)            (None, None, 256)         0         
_________________________________________________________________
lstm_1 (LSTM)                (None, None, 256)         525312    
_________________________________________________________________
dropout_1 (Dropout)          (None, None, 256)         0         
_________________________________________________________________
dense (Dense)                (None, None, 26)          6682      
=================================================================
Total params: 821,786
Trainable params: 821,786
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compile the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>

<span class="c1"># Fit the model</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch 1/50
59/59 [==============================] - 33s 554ms/step - loss: 1.8214
Epoch 2/50
59/59 [==============================] - 34s 582ms/step - loss: 1.4516
Epoch 3/50
59/59 [==============================] - 35s 596ms/step - loss: 1.1849
Epoch 4/50
59/59 [==============================] - 35s 588ms/step - loss: 0.9608
Epoch 5/50
59/59 [==============================] - 32s 544ms/step - loss: 0.8348
Epoch 6/50
59/59 [==============================] - 32s 546ms/step - loss: 0.7496
Epoch 7/50
59/59 [==============================] - 31s 531ms/step - loss: 0.6975
Epoch 8/50
59/59 [==============================] - 31s 525ms/step - loss: 0.6551
Epoch 9/50
59/59 [==============================] - 32s 545ms/step - loss: 0.6209
Epoch 10/50
59/59 [==============================] - 31s 529ms/step - loss: 0.5963
Epoch 11/50
59/59 [==============================] - 31s 531ms/step - loss: 0.5704
Epoch 12/50
59/59 [==============================] - 31s 532ms/step - loss: 0.5532
Epoch 13/50
59/59 [==============================] - 32s 544ms/step - loss: 0.5366
Epoch 14/50
59/59 [==============================] - 31s 532ms/step - loss: 0.5219
Epoch 15/50
59/59 [==============================] - 31s 531ms/step - loss: 0.5097
Epoch 16/50
59/59 [==============================] - 31s 529ms/step - loss: 0.4999
Epoch 17/50
59/59 [==============================] - 32s 543ms/step - loss: 0.4891
Epoch 18/50
59/59 [==============================] - 32s 546ms/step - loss: 0.4835
Epoch 19/50
59/59 [==============================] - 34s 575ms/step - loss: 0.4734
Epoch 20/50
59/59 [==============================] - 32s 539ms/step - loss: 0.4662
Epoch 21/50
59/59 [==============================] - 31s 533ms/step - loss: 0.4590
Epoch 22/50
59/59 [==============================] - 31s 532ms/step - loss: 0.4538
Epoch 23/50
59/59 [==============================] - 31s 533ms/step - loss: 0.4497
Epoch 24/50
59/59 [==============================] - 32s 538ms/step - loss: 0.4432
Epoch 25/50
59/59 [==============================] - 32s 537ms/step - loss: 0.4391
Epoch 26/50
59/59 [==============================] - 31s 532ms/step - loss: 0.4340
Epoch 27/50
59/59 [==============================] - 31s 530ms/step - loss: 0.4305
Epoch 28/50
59/59 [==============================] - 32s 538ms/step - loss: 0.4274
Epoch 29/50
59/59 [==============================] - 31s 529ms/step - loss: 0.4226
Epoch 30/50
59/59 [==============================] - 31s 531ms/step - loss: 0.4190
Epoch 31/50
59/59 [==============================] - 31s 528ms/step - loss: 0.4146
Epoch 32/50
59/59 [==============================] - 31s 534ms/step - loss: 0.4111
Epoch 33/50
59/59 [==============================] - 31s 527ms/step - loss: 0.4089
Epoch 34/50
59/59 [==============================] - 31s 528ms/step - loss: 0.4042
Epoch 35/50
59/59 [==============================] - 31s 529ms/step - loss: 0.4020
Epoch 36/50
59/59 [==============================] - 31s 531ms/step - loss: 0.3993
Epoch 37/50
59/59 [==============================] - 31s 528ms/step - loss: 0.3953
Epoch 38/50
59/59 [==============================] - 31s 527ms/step - loss: 0.3926
Epoch 39/50
59/59 [==============================] - 31s 532ms/step - loss: 0.3916
Epoch 40/50
59/59 [==============================] - 31s 530ms/step - loss: 0.3878
Epoch 41/50
59/59 [==============================] - 32s 542ms/step - loss: 0.3860
Epoch 42/50
59/59 [==============================] - 32s 539ms/step - loss: 0.3843
Epoch 43/50
59/59 [==============================] - 32s 538ms/step - loss: 0.3811
Epoch 44/50
59/59 [==============================] - 31s 525ms/step - loss: 0.3797
Epoch 45/50
59/59 [==============================] - 31s 533ms/step - loss: 0.3773
Epoch 46/50
59/59 [==============================] - 31s 525ms/step - loss: 0.3743
Epoch 47/50
59/59 [==============================] - 32s 534ms/step - loss: 0.3725
Epoch 48/50
59/59 [==============================] - 31s 526ms/step - loss: 0.3709
Epoch 49/50
59/59 [==============================] - 32s 541ms/step - loss: 0.3686
Epoch 50/50
59/59 [==============================] - 31s 526ms/step - loss: 0.3667
</pre></div>
</div>
</div>
<div class="section" id="interlude-how-to-store-and-load-keras-models">
<h2>Interlude: How to store and load keras models<a class="headerlink" href="#interlude-how-to-store-and-load-keras-models" title="Permalink to this headline">¶</a></h2>
<p>Your saved model will include:</p>
<ul class="simple">
<li><p>The model’s architecture/config</p></li>
<li><p>The model’s weight values (which were learned during training)</p></li>
<li><p>The model’s compilation information (if compile()) was called</p></li>
<li><p>The optimizer and its state, if any (this enables you to restart training where you left)</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Store to not having to train again...</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;twolayerlstm&quot;</span><span class="p">)</span>

<span class="c1"># Load to continue training or evaluate...</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;twolayerlstm&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">],</span> <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="png" src="../../_images/mg_output_25_1.png" /></p>
</div>
<div class="section" id="evaluation">
<h2>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">¶</a></h2>
<p>The average success rate on the training set is the percentage of characters correctly predicted by the network.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;Predictions&quot;&quot;&quot;</span>

<span class="c1"># Calculate predictions</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Compare to correct result</span>
<span class="n">train_res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Count correct and incorrect predictions</span>
<span class="n">no_false</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">train_res</span><span class="p">)</span>
<span class="n">no_true</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="o">*</span><span class="n">embed</span><span class="o">-</span><span class="n">no_false</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average success rate on training set: </span><span class="si">%s</span><span class="s2"> </span><span class="si">%%</span><span class="s2">&quot;</span> <span class="o">%</span><span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">no_true</span><span class="o">/</span><span class="p">(</span><span class="n">embed</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)),</span><span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Average success rate on training set: 87.76 %
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Take a look at the model predictions on the training set next to the true result</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">40</span><span class="p">):</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> 
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">pred</span><span class="o">=</span>  <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">int_to_char</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">idxs</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    
    <span class="c1"># Note that here we use the argmax and do not sample using the model output</span>
    
    <span class="n">idxs2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">true</span> <span class="o">=</span>  <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">int_to_char</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">idxs2</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <span class="k">if</span> <span class="n">true</span> <span class="o">!=</span> <span class="n">pred</span><span class="p">:</span>
        <span class="nb">print</span> <span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>CCCNC(=O)CSc1nnc(CC)n1NEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C(((C(=O)CSc1nnc(-))n1NEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE
c1nc(S(=O)(=O)N(C)C2CCCCC2)cn1CEEEEEEEEEEEEEEEEEEEEEE C1cc(NC=O)(=O)N2C)C)CCCCC2)c(1CEEEEEEEEEEEEEEEEEEEEEE
n1ccnc1SCC(=O)c1ccc(Cl)cc1ClEEEEEEEEEEEEEEEEEEEEEEEEE C1c((c1SCC(=O)N1ccc(Cl)cc1ElEEEEEEEEEEEEEEEEEEEEEEEEE
n1cc(CNC(=O)c2sc3cccc(Cl)c3c2Cl)cn1EEEEEEEEEEEEEEEEEE C1c((C(C(=O)c2cc3c(cccC))c3n2=))nc1EEEEEEEEEEEEEEEEEE
=c1oc2ccccc2cc1S(=O)(=O)c1ccc(F)cc1EEEEEEEEEEEEEEEEEE =C1cc2ccccc2c(1C(=O)(=O)c1ccc(C)cc1EEEEEEEEEEEEEEEEEE
=CC(O)C(Oc1ccccc1)n1nnc2ccccc21EEEEEEEEEEEEEEEEEEEEEE CCCNCcC(C)1ccccc1)C1nnc2ccccc21EEEEEEEEEEEEEEEEEEEEEE
=C(Nc1cccc2ncccc12)c1ccc2[nH]c(=O)c(=O)[nH]c2c1EEEEEE =C(Cc1cccccccnnc12)c1cccccnH]c(=O)[c=O)[nH]c2c1EEEEEE
OC(=O)c1ccc(NC(=O)CCn2c(=O)oc3ccccc32)cc1EEEEEEEEEEEE Cc(=O)c1ccc(NC(=O)COc2c(=O)oc3ccccc32)cc1EEEEEEEEEEEE
c1cc(SCC(N)=O)n2c(nc3ccccc32)c1CEEEEEEEEEEEEEEEEEEEEE C1cccC(C(=)=O)nnc3-c3ccccc32)n1CEEEEEEEEEEEEEEEEEEEEE
Oc1ccc(C2NC(=O)c3c(sc(C)c3C)N2)cc1EEEEEEEEEEEEEEEEEEE Cc1ccc(C(CC(=O)c3cccc3=)c3C)c2)cc1EEEEEEEEEEEEEEEEEEE
Oc1ccc(C(=O)c2nc3ccccc3n2C)cc1EEEEEEEEEEEEEEEEEEEEEEE Cc1ccc(C(=O)N2cc(ccccc3n2C)cc1EEEEEEEEEEEEEEEEEEEEEEE
lc1ccc(-c2noc(-c3ccncc3)n2)cc1EEEEEEEEEEEEEEEEEEEEEEE Cc1ccc(Cc2nnc(Cc3ccccc3)n2)cc1EEEEEEEEEEEEEEEEEEEEEEE
c1ccc(Cn2ccc(=O)c(OCc3ccccc3)c2C)cc1EEEEEEEEEEEEEEEEE C1ccc(C(2c(c(CO)c(=CC3ccccc3)n2N)cc1EEEEEEEEEEEEEEEEE
CC1Sc2sc(=O)sc2SC(CC)C1=OEEEEEEEEEEEEEEEEEEEEEEEEEEEE C((Cc2cc(NO)cc2N((=)(C1=OEEEEEEEEEEEEEEEEEEEEEEEEEEEE
C(=O)NCCc1nc2ccccc2n1Cc1ccccc1EEEEEEEEEEEEEEEEEEEEEEE C(=O)NcCC1cc2ccccc2n1Cc1ccccc1EEEEEEEEEEEEEEEEEEEEEEE
c1ccccc1OCCCC(=O)Nc1nccs1EEEEEEEEEEEEEEEEEEEEEEEEEEEE C1ccc((1NCC(N(=O)Nc1cccs1EEEEEEEEEEEEEEEEEEEEEEEEEEEE
1ccc2c(c1)NC(c1ccc3c(c1)OCO3)n1nnnc1-2EEEEEEEEEEEEEEE 1ccc(c(c1)N((=1ccccc(c1)OCO3)C1cccc1-2EEEEEEEEEEEEEEE
C(=O)c1ccc(NC(=O)N2CCc3ccccc3C2)cc1EEEEEEEEEEEEEEEEEE C(=O)N1ccc(NC(=O)CcCCC3ccccc322)cc1EEEEEEEEEEEEEEEEEE
COC(=O)CSc1nc(C)c(Oc2ccccc2)c(=O)[nH]1EEEEEEEEEEEEEEE C(C(=O)c1c1nn2-)c(CC2ccccc2)n(=O)[nH]1EEEEEEEEEEEEEEE
C(=O)Oc1cccc(C(=O)Nc2cccc(C)n2)c1EEEEEEEEEEEEEEEEEEEE C(=O)Nc1ccc((C(=O)Nc2cccccC(c2)c1EEEEEEEEEEEEEEEEEEEE
=C(NCc1ccccc1)c1noc2c1CCc1ccccc1-2EEEEEEEEEEEEEEEEEEE =C(Ccc1ccccc1)c1ccc2c1CCC2ccccc122EEEEEEEEEEEEEEEEEEE
N(C)c1ccc(C(=O)CC2(O)C(=O)Nc3ccccc32)cc1EEEEEEEEEEEEE C(C)C1ccc(C(=O)NOC(C)C(=O)Nc3ccccc32)cc1EEEEEEEEEEEEE
c1cc(C)n2c(SCC(=O)NCC(F)(F)F)nnc2n1EEEEEEEEEEEEEEEEEE C1cccC)c(n(SCC(=O)NCc3=)(F)F)ncc2n1EEEEEEEEEEEEEEEEEE
COc1cccc(C2C(C(N)=O)C(C)=Nc3nnnn32)c1EEEEEEEEEEEEEEEE C(C1ccc(cC(CC=)F)=O)C(=)(OC3ncnn32)c1EEEEEEEEEEEEEEEE
Oc1ccc(N(CC(=O)N2CCCCCC2)S(C)(=O)=O)cc1EEEEEEEEEEEEEE Cc1ccc(CCCC(=O)NCCCCCC22)C(C)(=O)=O)cc1EEEEEEEEEEEEEE
Oc1cccc(CC(=O)Nc2nc3c(s2)C(=O)CC(C)(C)C3)c1EEEEEEEEEE Cc1ccc(cC((=O)Nc2cc(ccs2)CCCO)CC3C)CC)C3)c1EEEEEEEEEE
=S(=O)(Cc1cc(-c2ccccc2)n[nH]1)c1ccccc1EEEEEEEEEEEEEEE =C(=O)(Nc1cccCc2ccccc2)nonH]1)N1ccccc1EEEEEEEEEEEEEEE
c1cccc(-n2ncc3c(=O)n(Cc4ccccn4)cnc32)c1CEEEEEEEEEEEEE C1ccc((Nc2nnc3c(=O)n(CC4ccccc4)nnc32)c1EEEEEEEEEEEEEE
CCNC(=O)Cn1nc(CC)n2c(cc3occc32)c1=OEEEEEEEEEEEEEEEEEE C((C(=O)CS1cn(C()ccc3=c3cccc32)c1=OEEEEEEEEEEEEEEEEEE
c1cc(Cl)ccc1OC(C)C(=O)Nc1ccc(C(N)=O)cc1EEEEEEEEEEEEEE C1cccC))ccc1NCCC)C(=O)NC1ccccCEN)=O)cc1EEEEEEEEEEEEEE
=C(Cn1nc(-c2cccs2)ccc1=O)Nc1nccs1EEEEEEEEEEEEEEEEEEEE =C(CO1cn(-c2cccc2)ccc1=O)NC1cccs1EEEEEEEEEEEEEEEEEEEE
CNC(=O)n1cc(-c2ccnc3ccccc23)c(-c2ccccn2)n1EEEEEEEEEEE C(((=O)C1c((-c2cccccccccc23)n(Cc2ccccc2)n1EEEEEEEEEEE
COC(=O)NS(=O)(=O)c1ccc(OC)cc1EEEEEEEEEEEEEEEEEEEEEEEE C(C(=O)c1c=O)(=O)c1ccc(CC)c(1EEEEEEEEEEEEEEEEEEEEEEEE
OC(=O)c1cnn2c(C(F)(F)Cl)cc(C)nc12EEEEEEEEEEEEEEEEEEEE Cc(=O)c1ccc(c(-(F)(F)Fl)cc(C(n112EEEEEEEEEEEEEEEEEEEE
Oc1cc(N)c(-c2nc3ccccc3[nH]2)cc1OCEEEEEEEEEEEEEEEEEEEE Cc1cccCCc(Cc2cn3ccccc3nnH]2)cc1OCEEEEEEEEEEEEEEEEEEEE
COc1ccccc1NC(=O)CSc1ccc2c(c1)OCCO2EEEEEEEEEEEEEEEEEEE C(C1ccc(c1NC(=O)COc1ncccc(c1)OCOO2EEEEEEEEEEEEEEEEEEE
COCCOc1cccc(C(=O)NC2CCCCC2)c1EEEEEEEEEEEEEEEEEEEEEEEE C(C(NC1ccc(cC(=O)NC2CCCCC2)c1EEEEEEEEEEEEEEEEEEEEEEEE
c1nc(COc2ccc(Cl)cc2Cl)n[nH]1EEEEEEEEEEEEEEEEEEEEEEEEE E1cc(N(c2ccccCl)cc2)l)nnnH]1EEEEEEEEEEEEEEEEEEEEEEEEE
Oc1ccc(-c2csnn2)cc1S(=O)(=O)Nc1ccccc1EEEEEEEEEEEEEEEE Cc1ccc(Cc2nccc2)c(1C(=O)(=O)NC1ccccc1EEEEEEEEEEEEEEEE
</pre></div>
</div>
<p>To generate a sequence of SMILES characters starting from a single start character until the end letter ”E” appears requires a sampling step, where we use the probability distribution over the characters produced by the network at each step to sample the next letter.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gen_mol</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">start_char</span><span class="p">):</span>
    <span class="c1"># Array of probabilities</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Start character</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">26</span><span class="p">))</span>
    <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">char_to_int</span><span class="p">[</span><span class="n">start_char</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">stringc</span> <span class="o">=</span> <span class="n">start_char</span>
    
    <span class="c1"># Predict first character by randomly sampling from model output</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">ch</span> <span class="o">=</span> <span class="n">int_to_char</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">char_to_int</span><span class="p">)),</span> <span class="n">p</span><span class="o">=</span><span class="n">pred</span><span class="p">)]</span>
    <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
    <span class="n">stringc</span> <span class="o">+=</span> <span class="n">ch</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">26</span><span class="p">))</span>
    <span class="n">x1</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">char_to_int</span><span class="p">[</span><span class="n">ch</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">x1</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Continue as long as we do not add &#39;E&#39;</span>
    <span class="k">while</span> <span class="n">ch</span> <span class="o">!=</span><span class="s1">&#39;E&#39;</span><span class="p">:</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:],</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">ch</span> <span class="o">=</span> <span class="n">int_to_char</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">char_to_int</span><span class="p">)),</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">pred</span><span class="p">)]</span>
        <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>

        <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">26</span><span class="p">))</span>
        <span class="n">x1</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">char_to_int</span><span class="p">[</span><span class="n">ch</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">x1</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">stringc</span> <span class="o">+=</span> <span class="n">ch</span>
        

    <span class="nb">print</span><span class="p">(</span><span class="n">stringc</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s try it out!</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">gen_mol</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>CCCO=CO=C)CO=CCCc1)(=CO=NE
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot probability distributions with opacity given by the order in the sequence</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">)):</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">preds</span><span class="p">[</span><span class="n">i</span><span class="p">,:],</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>       

<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">char_to_int</span><span class="p">)))</span>    
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">char_to_int</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Prob.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="png" src="../../_images/mg_output_34_0.png" /></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># The longer the sequence gets, the higher the probability of &#39;E&#39; should get.</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">preds</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;-o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Prob.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Sequence length&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="png" src="../../_images/mg_output_35_0.png" /></p>
<hr class="docutils" />
<dl class="footnote brackets">
<dt class="label" id="id3"><span class="brackets"><a class="fn-backref" href="#id1">3</a></span></dt>
<dd><p>https://github.com/molecularsets/moses</p>
</dd>
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id2">4</a></span></dt>
<dd><p>https://www.rdkit.org/docs/index.html#</p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs/unsupervised_learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="Denoising.html" title="previous page">Exercise: Denoising with Restricted Boltzmann Machines</a>
    <a class='right-next' id="next-link" href="Anomaly_Detection_RNN_AE_VAE.html" title="next page">Exercise: Anomaly Detection</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Eliska<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>