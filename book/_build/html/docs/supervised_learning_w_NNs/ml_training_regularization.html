
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Training &#8212; Machine Learning for Scientists</title>
    
  <link rel="stylesheet" href="../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Regularization" href="ml_convolutional.html" />
    <link rel="prev" title="Computational neurons" href="ml_intro_neural.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/cluster.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Machine Learning for Scientists</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Lecture
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../structuring_data/ml_without_neural_network.html">
   Structuring Data without Neural Networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../structuring_data/ml_without_neural_network-1.html">
     Principle Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../structuring_data/ml_without_neural_network-2.html">
     Kernel PCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../structuring_data/ml_without_neural_network-3.html">
     t-SNE as a Nonlinear Visualization Technique
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../structuring_data/ml_without_neural_network-4.html">
     Clustering Algorithms: the example of
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -means
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../structuring_data/pca.html">
     Exercise: Principle Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../structuring_data/Dimensionality_reduction.html">
     Exercise: Dimensionality Reduction
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../supervised_learning_wo_NNs/ml_supervised_wo_NNs.html">
   Supervised Learning without Neural Networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_wo_NNs/ml_supervised_wo_NNs-1.html">
     Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_wo_NNs/ml_supervised_wo_NNs-2.html">
     Binary Classification and Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_wo_NNs/ml_supervised_wo_NNs-3.html">
     More than two classes: Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_wo_NNs/Linear-regression.html">
     Exercise: Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../supervised_learning_wo_NNs/Classification.html">
     Exercise: Classification without Neural Networks
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="ml_supervised_w_NNs.html">
   Supervised Learning with Neural Networks
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="ml_intro_neural.html">
     Computational neurons
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Training
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ml_convolutional.html">
     Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ml_rnn.html">
     Recurrent neural networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Classification-2.html">
     Exercise: Dense Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NN-opt-reg.html">
     Exercise: Machine Learning Optimizers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NN-opt-reg.html#exercise-learning-rate-scheduling">
     Exercise: Learning Rate Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NN-opt-reg.html#exercise-regularizing-neural-networks">
     Exercise: Regularizing Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="CNNs.html">
     Exercise: Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="exoplanets_RNN_CNN.html">
     Exercise: Discovery of Exoplanets with RNNs and CNNs
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../unsupervised_learning/ml_unsupervised.html">
   Unsupervised Learning
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../unsupervised_learning/ml_unsupervised-1.html">
     Restricted Boltzmann Machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unsupervised_learning/ml_unsupervised-2.html">
     Training an RNN without Supervision
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unsupervised_learning/ml_unsupervised-3.html">
     Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unsupervised_learning/ml_unsupervised-4.html">
     Generative Adversarial Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unsupervised_learning/Denoising.html">
     Exercise: Denoising with Restricted Boltzmann Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unsupervised_learning/Molecule_gen_RNN.html">
     Exercise: Molecule Generation with an RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unsupervised_learning/Anomaly_Detection_RNN_AE_VAE.html">
     Exercise: Anomaly Detection
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../interpretability/ml_interpretability.html">
   Interpretability of Neural Networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../interpretability/ml_interpretability-1.html">
     Dreaming and the Problem of Extrapolation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../interpretability/ml_interpretability-2.html">
     Adversarial Attacks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../interpretability/ml_interpretability-3.html">
     Interpreting Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../interpretability/Transfer-learning-attacks.html">
     Exercise: Transfer Learning and Adversarial Attacks
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../reinforcement_learning/ml_reinforcement-learning.html">
   Reinforcement Learning
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../reinforcement_learning/ml_reinforcement-learning-1.html">
     Exploration versus Exploitation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reinforcement_learning/ml_reinforcement-learning-2.html">
     Finite Markov Decision Process
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reinforcement_learning/ml_reinforcement-learning-3.html">
     Policies and Value Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reinforcement_learning/ml_reinforcement-learning-4.html">
     Temporal-difference Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reinforcement_learning/ml_reinforcement-learning-5.html">
     Function Approximation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../conclusion/ml_conclusion.html">
   Concluding Remarks
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  About us
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../about_us.html">
   Who we are
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/docs/supervised_learning_w_NNs/ml_training_regularization.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simple-example-mnist">
   Simple example: MNIST
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="training">
<span id="sec-training"></span><h1>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h1>
<p>Adjusting all the weights and biases to achieve the task given using
data samples
<span class="math notranslate nohighlight">\(\mathcal{D}= \{({\boldsymbol{x}}_1,{\boldsymbol{y}}_1),\dots, ({\boldsymbol{x}}_m,{\boldsymbol{y}}_m)\}\)</span>
constitutes the <em>training</em> of the network. In other words, the training
is the process that makes the network an approximation to the
mathematical function
<span class="math notranslate nohighlight">\({\boldsymbol{F}}({\boldsymbol{x}}) = {\boldsymbol{y}}\)</span> that we want it
to represent. Since each neuron has its own bias and weights, a
potentially huge number of variatonial parameters, and we will need to
adjust all of them.</p>
<p>We have already seen in the previous chapter how one in principle trains
a variational function. For the purpose of learning, we introduce a
<em>loss function</em> <span class="math notranslate nohighlight">\(L(W,B)\)</span>, which characterizes how well the network is
doing at predicting the correct output for each input. The loss function
now depends, through the neural network, on all the weights and biases
that we collectively denote by the vectors <span class="math notranslate nohighlight">\(W\)</span> and <span class="math notranslate nohighlight">\(B\)</span>.</p>
<p>The choice of loss function may strongly impact the efficiency of the
training and is based on heuristics (as was the case with the choice of
activation functions). In the previous chapter, we already encountered
one loss function, the mean square error</p>
<div class="math notranslate nohighlight">
\[L(\theta) = \frac{1}{2m}\sum_{i=1}^m||{\boldsymbol{F}}({\boldsymbol{x}}_i) - {\boldsymbol{y}}_i ||_2^2.
    \label{eq:MSE}\]</div>
<p>Here, <span class="math notranslate nohighlight">\(||{\boldsymbol{a}}||_2=\sqrt{\sum_i a_i^2}\)</span>
is the <span class="math notranslate nohighlight">\(L2\)</span> norm and thus, this loss function is also referred to as
<em><span class="math notranslate nohighlight">\(L2\)</span> loss</em>. An advantage of the L2 loss is that it is a smooth function
of the variational parameters. Another natural loss function is the
<em>mean absolute error</em>, which is given by</p>
<div class="math notranslate nohighlight">
\[L(\theta) = \frac{1}{2m}\sum_{i=1}^m||{\boldsymbol{F}}({\boldsymbol{x}}_i) - {\boldsymbol{y}}_i ||_1,
    \label{eq:MAE}\]</div>
<p>where <span class="math notranslate nohighlight">\(||{\boldsymbol{a}}||_1 = \sum_i |a_i|\)</span>
denotes the <span class="math notranslate nohighlight">\(L1\)</span> norm. This loss function is thus also called the <em><span class="math notranslate nohighlight">\(L1\)</span>
loss</em>. Note that the <span class="math notranslate nohighlight">\(L2\)</span> norm, given the squares, puts more weight on
outliers than the <span class="math notranslate nohighlight">\(L1\)</span> loss. The two loss functions introduced so far
are the most common loss functions for networks providing a continuous
output. For discrete classification problems, a great choice is the
<em>cross-entropy</em> between true label, <span class="math notranslate nohighlight">\({\boldsymbol{y}}_i\)</span> and the network
output, <span class="math notranslate nohighlight">\({\boldsymbol{F}}({\boldsymbol{x}}_i)\)</span> defined as</p>
<div class="math notranslate nohighlight" id="equation-eq-cross-entropy">
<span class="eqno">(35)<a class="headerlink" href="#equation-eq-cross-entropy" title="Permalink to this equation">¶</a></span>\[L_{\mathrm{ent}}{}(\theta)
    =-\sum_{i=1}^m
    \left[
    {\boldsymbol{y}}_i\cdot
    \ln \left(
    {\boldsymbol{F}}({\boldsymbol{x}}_i)
    \right)
+
   (1- {\boldsymbol{y}}_i)\cdot
    \ln \left(1-
    {\boldsymbol{F}}({\boldsymbol{x}}_i)
    \right)
    \right]
    ,\]</div>
<p>where the logarithm is taken element-wise. This loss function is also called <em>negative log
likelihood</em>. It is here written for outputs that lie between 0 and 1, as
is the case when the activation function of the last layer of the
network is sigmoid <span class="math notranslate nohighlight">\(\sigma(z)=1/(1+e^{-z})\)</span>. (The cross-entropy is
preferably combined with sigmoid activation in the last layer.)</p>
<p>Of these loss functions the cross entropy is probably the least
intuitive one. We want to understand what it means and gain some
intuition about it. The different cost functions actually differ by the
speed of the learning process. The learning rate is largely determined
by the partial derivatives of the cost function
<span class="math notranslate nohighlight">\(\partial L/\partial \theta\)</span>. Slow learning appears when these
derivatives become small. Let us consider the toy example of a single
neuron with sigmoid activation <span class="math notranslate nohighlight">\(F(x)=\sigma(wx+b)\)</span> and a single
input-output pair <span class="math notranslate nohighlight">\(\{x,y\}=\{1,0\}\)</span>. Then the quadratic cost function
has derivatives</p>
<div class="math notranslate nohighlight">
\[ \frac{\partial L}{\partial w}=
\frac{\partial L}{\partial b}=\sigma(w+b)\sigma'(w+b).\]</div>
<p>We observe that this derivative gets very small for <span class="math notranslate nohighlight">\(\sigma(w+b)\to 1\)</span>, because
<span class="math notranslate nohighlight">\(\sigma'\)</span> gets very small in that limit. Therefore, a slowdown of
learning appears. This slowdown is also observed in more complex neural
networks with L2 loss, we considered the simple case here only to be
able to say something analytically.</p>
<p>Given this observation, we want to see whether the cross entropy can
improve the situation. We again compute the derivative of the cost
function with respect to the weights for a single term in the sum and a
network that is composed of a single sigmoid and a general input-output
pair <span class="math notranslate nohighlight">\(\{x,y\}\)</span></p>
<div class="math notranslate nohighlight" id="equation-eqn-cost-derivative-w">
<span class="eqno">(36)<a class="headerlink" href="#equation-eqn-cost-derivative-w" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
  \frac{\partial L_{\mathrm{ent}}}{\partial w}
  &amp;=-\left(
    \frac{y}{\sigma(wx+b)}-\frac{1-y}{1-\sigma(wx+b)}\right)\sigma'(wx+b)x
    \\
    &amp;=\frac{\sigma'(wx+b) x}{\sigma(wx+b)[1-\sigma(wx+b)]}[\sigma(wx+b)-y]
    \\
    &amp;=x[\sigma(wx+b)-y],
\end{split}\end{split}\]</div>
<p>where in the last step we used that
<span class="math notranslate nohighlight">\(\sigma'(z)=\sigma(z)[1-\sigma(z)]\)</span>. This is a much better result than
what we got for the L2 loss. The learning rate is here directly
proportional to the error between data point and prediction
<span class="math notranslate nohighlight">\([\sigma(wx+b)-y]\)</span>. The mathematical reason for this change is that
<span class="math notranslate nohighlight">\(\sigma'(z)\)</span> cancels out due to this specific form of the cross entropy.
A similar expression holds true for the derivative with respect to <span class="math notranslate nohighlight">\(b\)</span>,</p>
<div class="math notranslate nohighlight" id="equation-eq-cost-derivative-b">
<span class="eqno">(37)<a class="headerlink" href="#equation-eq-cost-derivative-b" title="Permalink to this equation">¶</a></span>\[  \frac{\partial L_{\mathrm{ent}}}{\partial b}=[\sigma(wx+b)-y].\]</div>
<p>In fact, if we insisted that we want the
very intuitive form of Eqs <a class="reference internal" href="#equation-eq-cost-derivative-b">(37)</a> and <a class="reference internal" href="#equation-eqn-cost-derivative-w">(36)</a> for the gradients, we can derive the
cost function for the sigmoid activation function to be the
cross-entropy. This follows simply because</p>
<div class="math notranslate nohighlight">
\[\frac{\partial L}{\partial b}=\frac{\partial L}{\partial F}F'\]</div>
<p>and <span class="math notranslate nohighlight">\(F'=F(1-F)\)</span> for the sigmoid activation, which, in comparison to <a class="reference internal" href="#equation-eqn-cost-derivative-w">(36)</a> ,
yields <span class="math notranslate nohighlight">\(\frac{\partial L}{\partial F}=\frac{F-y}{F(1-F)},\)</span> which, when
integrated with respect to <span class="math notranslate nohighlight">\(F\)</span>, gives exactly the cross-entropy (up to a
constant). We can thus, starting from Eqs. <a class="reference internal" href="#equation-eqn-cost-derivative-w">(36)</a> and <a class="reference internal" href="#equation-eq-cost-derivative-b">(37)</a>, think of the choice of
cost functions as a backward engineering. Following this logic, we can
think of other pairs of final layer activations and cost functions that
may work well together.</p>
<p>What happens if we change the activation function in the last layer from
sigmoid to softmax? For the loss function, we consider just the first
term in the cross entropy for the shortness of presentation (for
softmax, this form is appropriate, as compared to a sigmoid activation)</p>
<div class="math notranslate nohighlight">
\[L(\theta)
    =-\sum_{i=1}^m
    {\boldsymbol{y}}_i\cdot
    \ln \left(
    {\boldsymbol{F}}({\boldsymbol{x}}_i)
    \right)
    ,
    \label{eq:cross-entropy 2}\]</div>
<p>where again the logarithm is taken
element-wise. For concreteness, let us look at one-hot encoded
classification problem. Then, all <span class="math notranslate nohighlight">\({\boldsymbol{y}}_i\)</span> labels are
vectors with exactly one entry “1”. Let that entry have index <span class="math notranslate nohighlight">\(n_i\)</span> in
the vector. The loss function then reads</p>
<div class="math notranslate nohighlight">
\[L(\theta)
    =-\sum_{i=1}^m
    \ln \left(
    F_{n_i}({\boldsymbol{x}}_i)
    \right)
    .
    \label{eq:cross-entropy 3}\]</div>
<p>Due to the properties of the softmax,
<span class="math notranslate nohighlight">\( F_{n_i}({\boldsymbol{x}}_i)\)</span> is always <span class="math notranslate nohighlight">\(\leq 1\)</span>, so that loss function
is minimized, if it approaches 1, the value of the label. For the
gradients, we obtain</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{split}
\frac{\partial L}{\partial b_{j}}=&amp;
-\sum_{i=1}^m\frac{1}{F_{n_i}({\boldsymbol{x}}_i)}\frac{\partial F_{n_i}({\boldsymbol{x}}_i)}{\partial b_j}
\\
=&amp;
-\sum_{i=1}^m\frac{1}{F_{n_i}({\boldsymbol{x}}_i)}
\left[
F_{n_i}({\boldsymbol{x}}_i)\delta_{n_i,j}
-F_{n_i}({\boldsymbol{x}}_i)^2
\right]
\\
=&amp;
\sum_{i=1}^m
\left[
F_{n_i}({\boldsymbol{x}}_i)
-y_{n_i}
\right].
\end{split}\end{split}\]</div>
<p>We observe that again, the gradient has a similar
favorable structure to the previous case, in that it is linearly
dependent on the error that the network makes. (The same can be found
for the derivatives with respect to the weights.)</p>
<p>Once we have defined a loss function, we also already understand how to
train the network: we need to minimize <span class="math notranslate nohighlight">\(L(\theta)\)</span> with respect to <span class="math notranslate nohighlight">\(W\)</span>
and <span class="math notranslate nohighlight">\(B\)</span>. However, <span class="math notranslate nohighlight">\(L\)</span> is typically a high-dimensional function and may
have many nearly degenerate minima. Unlike in the previous chapter,
finding the loss function’s absolute minimum exactly is typically
intractable analytically and may come at prohibitive costs
computationally. The practical goal is therefore rather to find a “good”
instead than the absolute minimum through training. Having found such
“good” values for <span class="math notranslate nohighlight">\(W,B\)</span>, the network can then be applied on previously
unseen data.</p>
<p>It remains to be explained how to minimize the loss function. Here, we
employ an iterative method called <em>gradient descent</em>. Intuitively, the
method corresponds to “walking down the hill” in our many parameter
landscape until we reach a (local) minimum. For this purpose, we use the
(discrete) derivative of the cost function to update all the weights and
biases incrementally and search for the minimum of the function via tiny
steps on the many-dimensional surface. More specifically, we can update
all weights and biases in each step as</p>
<div class="math notranslate nohighlight">
\[ \begin{aligned}
 \theta_\alpha \rightarrow  \theta_\alpha - \eta \frac{\partial L(\theta)}{\partial  \theta_\alpha}.
 \end{aligned}\]</div>
<p>The variable <span class="math notranslate nohighlight">\(\eta\)</span>, also referred to as <em>learning
rate</em>, specifies the size of step we use to walk the landscape—if it is
too small in the beginning, we might get stuck in a local minimum early
on, while for too large <span class="math notranslate nohighlight">\(\eta\)</span> we might never find a minimum. The
learning rate is a hyperparameter of the training algorithm. Note that
gradient descent is just a discrete many-variable version of the
analytical search for extrema which we know from calculus: An extremum
is characterized by vanishing derivatives in all directions, which
results in convergence in the gradient descent algorithm outlined above.</p>
<p>While the process of optimizing the many variables of the loss function
is mathematically straightforward to understand, it presents a
significant numerical challenge: For each variational parameter, for
instance a weight in the <span class="math notranslate nohighlight">\(k\)</span>-th layer <span class="math notranslate nohighlight">\(W_{ij}^{[k]}\)</span>, the partial
derivative <span class="math notranslate nohighlight">\(\partial L/ \partial W_{ij}^{[k]}\)</span> has to be computed. And
this has to be done each time the network is evaluated for a new dataset
during training. Naively, one could assume that the whole network has to
be evaluated each time. Luckily there is an algorithm that allows for an
efficient and parallel computation of all derivatives – it is known as
<em>backpropagation</em>. The algorithm derives directly from the chain rule of
differentiation for nested functions and is based on two observations:</p>
<ul>
<li><p>The loss function is a function of the neural network
<span class="math notranslate nohighlight">\(F({\boldsymbol{x}})\)</span>, that is <span class="math notranslate nohighlight">\(L \equiv L(F)\)</span>.</p></li>
<li><p>To determine the derivatives in layer <span class="math notranslate nohighlight">\(k\)</span> only the derivatives of
the following layer, given as Jacobi matrix</p>
<div class="math notranslate nohighlight">
\[D{\boldsymbol{f}}^{[l]}({\boldsymbol{z}}^{[l-1]}) = \partial {\boldsymbol{f}}^{[l]}/\partial {\boldsymbol{z}}^{[l-1]},\]</div>
<p>with <span class="math notranslate nohighlight">\(l&gt;k\)</span> and <span class="math notranslate nohighlight">\(z^{[l-1]}\)</span> the output of the previous layer, as well
as</p>
<div class="math notranslate nohighlight">
\[\begin{split}\frac{\partial {\boldsymbol{z}}^{[k]} }{ \partial \theta_\alpha^{[k]}} =
        \frac{\partial {\boldsymbol{g}}^{[k]}}{\partial q_i^{[k]}}
        \frac{{\partial q_i^{[k]}}}{\partial\theta_\alpha}
        =
        \begin{cases}
        \frac{\partial {\boldsymbol{g}}^{[k]}}{\partial q_i^{[k]}} z^{[k-1]}_j&amp;\theta_\alpha=W_{ij}
        \\
        \frac{\partial {\boldsymbol{g}}^{[k]}}{\partial q_i^{[k]}} &amp;\theta_\alpha=b_{i}
        \end{cases}\end{split}\]</div>
</li>
</ul>
<p>are required. The derivatives <span class="math notranslate nohighlight">\({\boldsymbol{z}}^{[l]}\)</span> are the same for all parameters.</p>
<p>The calculation of the Jacobi matrix thus has to be performed only once
for every update. In contrast to the evaluation of the network itself,
which is propagating forward, (output of layer <span class="math notranslate nohighlight">\(n\)</span> is input to layer
<span class="math notranslate nohighlight">\(n+1\)</span>), we find that a change in the Output propagates backwards though
the network. Hence the name<a class="footnote-reference brackets" href="#id3" id="id1">3</a>.</p>
<p>The full algorithm looks then as follows:</p>
<div class="admonition-backpropagation admonition" id="alg-backpropagation">
<p class="admonition-title">Backpropagation</p>
<p>Input: Loss function <span class="math notranslate nohighlight">\(L\)</span> that in turn depends on the neural network, which is parametrized by weights and biases, summarized as <span class="math notranslate nohighlight">\(\theta=\{W,b\}\)</span></p>
<p>Output: Partial derivatives <span class="math notranslate nohighlight">\(\partial L / \partial \theta^{[n]}_{\alpha}\)</span> with respect to all parameters  <span class="math notranslate nohighlight">\(\theta^{[n]}\)</span> of all layers <span class="math notranslate nohighlight">\(k=1\dots n\)</span>.</p>
<p>Calculate the derivatives with respect to the
parameters of the output layer:
<span class="math notranslate nohighlight">\(\partial L / \partial W^{[n]}_{ij} = ({\boldsymbol{\nabla}} L)^T
 \frac{\partial {\boldsymbol{g}}^{[n]}}{\partial q_i^{[n]}} z^{[n-1]}_j
\)</span>,
<span class="math notranslate nohighlight">\(\quad\partial L / \partial b^{[n]}_{i} = ({\boldsymbol{\nabla}} L)^T \frac{\partial {\boldsymbol{g}}^{[n]}}{\partial q_i^{[n]}}\)</span></p>
<p>for <span class="math notranslate nohighlight">\(k = 1, ..., n\)</span> do
Calculate the Jacobi matrices for layer <span class="math notranslate nohighlight">\(k\)</span>: <span class="math notranslate nohighlight">\(D{g}^{[k]}=(\partial {g}^{[k]}/\partial {q}^{[k]})\)</span> and <span class="math notranslate nohighlight">\(D{f}^{[k]}=(\partial {f}^{[k]}/\partial {z}^{[k-1]})\)</span>;
Multiply all following Jacobi matrices to obtain the derivatives of layer <span class="math notranslate nohighlight">\(k\)</span>:
<span class="math notranslate nohighlight">\(\partial L / \partial \theta^{[k]}_{\alpha} = (\nabla L)^T D{f}^{[n]}\cdots D{f}^{[k+1]}D{g}^{[k]} (\partial {q}^{[k]}/\partial \theta^{[k]}_\alpha)\)</span></p>
</div>
<p>A remaining question is when to actually perform updates to the network
parameters. One possibility would be to perform the above procedure for
each training data individually. Another extreme is to use all the
training data available and perform the update with an averaged
derivative. Not surprisingly, the answer lies somewhere in the middle:
Often, we do not present training data to the network one item at the
time, but the full training data is divided into co-called <em>batches</em>, a
group of training data that is fed into the network together. Chances
are the weights and biases can be adjusted better if the network is
presented with more information in each training step. However, the
price to pay for larger batches is a higher computational cost.
Therefore, the batch size can greatly impact the efficiency of training.
The random partitioning of the training data into batches is kept for a
certain number of iterations, before a new partitioning is chosen. The
consecutive iterations carried out with a chosen set of batches
constitute a training <em>epoch</em>.</p>
<div class="section" id="simple-example-mnist">
<h2>Simple example: MNIST<a class="headerlink" href="#simple-example-mnist" title="Permalink to this headline">¶</a></h2>
<p>As we discussed in the introduction, the recognition of hand-written
digits <span class="math notranslate nohighlight">\(0\)</span>, <span class="math notranslate nohighlight">\(1\)</span>, <span class="math notranslate nohighlight">\(\ldots 9\)</span> is the “Drosophila” of machine learning with
neural networks. There is a dataset with tens of thousands of examples
of hand-written digits, the so-called MNIST data set. Each data sample
in the MNIST dataset, a <span class="math notranslate nohighlight">\(28\times28\)</span> grayscale image, comes with a
<em>label</em>, which holds the information which digit is stored in the image.
The difficulty of learning to recognize the digits is that handwriting
styles are incredibly personal and different people will write the digit
“4” slightly differently. It would be very challenging to hardcode all
the criteria to recognize “4” and not confuse it with, say, a “9”.</p>
<p>We can use a simple neural network as introduced earlier in the chapter
to tackle this complex task. We will use a network as shown in
<a class="reference internal" href="ml_intro_neural.html#fig-simple-network"><span class="std std-numref">Fig. 14</span></a> and given in Eq. <a class="reference internal" href="ml_intro_neural.html#equation-eq-2-layer-nn">(34)</a> to do just that. The
input is the image of the handwritten digit, transformed into a <span class="math notranslate nohighlight">\(k=28^2\)</span>
long vector, the hidden layer contains <span class="math notranslate nohighlight">\(l\)</span> neurons and the output layer
has <span class="math notranslate nohighlight">\(p=10\)</span> neurons, each corresponding to one digit in the one-hot
encoding. The output is then a probability distribution over these 10
neurons that will determine which digit the network identifies.</p>
<p>As an exercise, we build a neural network according to these guidelines
and train it. How exactly one writes the code depends on the library of
choice , but the generic structure will be the following:</p>
<div class="admonition-mnist admonition" id="alg-mnist">
<p class="admonition-title">MNIST</p>
<ol class="simple">
<li><p><em>Import the data</em>: The MNIST database is available for download at
<a class="reference external" href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></p></li>
<li><p><em>Define the model</em>:</p>
<ul class="simple">
<li><p><em>Input layer</em>: <span class="math notranslate nohighlight">\(28^2=784\)</span> neurons (the greyscale value of each
pixel of the image, normalized to a value in <span class="math notranslate nohighlight">\([0,1)\)</span>, is one
component of the input vector).</p></li>
<li><p><em>Fully connected hidden layer</em>: Here one can experiment,
starting from as few as 10 neurons. The use of a sigmoid
activation function is recommended, but others can in principle
be used.</p></li>
<li><p><em>Output layer</em>: Use 10 neurons, one for each digit. The proper
activation function for this classification task is, as
discussed, a softmax function.</p></li>
</ul>
</li>
<li><p><em>Choose the loss function</em>: Since we are dealing with a
classification task, we use the cross-entropy, Eq. <a class="reference internal" href="#equation-eq-cross-entropy">(35)</a>.</p></li>
<li><p><em>Train and evaluate the model</em>: Follow the standard machine-learning
workflow to train<a class="footnote-reference brackets" href="#id4" id="id2">4</a> and evaluate the model. However, unlike in the
regression example of the previous chapter, where we evaluated the
model using the mean square error, here we are rather interested in
the accuracy of our prediction.</p></li>
</ol>
</div>
<p>With the training completed, we want to understand how well the final
model performs in recognizing handwritten digits. For that, we introduce
the <em>accuracy</em> defined by</p>
<div class="math notranslate nohighlight">
\[\text{accuracy} = \frac{\text{correct predictions}}{\text{total predictions}}.
    \label{eq:accuracy}\]</div>
<p>If we use 30 hidden neurons, set the learning
rate to <span class="math notranslate nohighlight">\(\eta=0.5\)</span> (a mini-batch size of 10 and train for 30 epochs), we
obtain an accuracy of 95.49 %. With a quadratic cost we obtain only
slightly worse results of 95.42%. For 100 hidden neurons, we obtain
96.82%. That is a considerable improvement over a quadratic cost, where
we obtain 96.59%. (Meaning that now about 1 in 14 wrongly classified
pictures will now be correctly classified.) Still, these numbers are not
even close to state of the art neural network performances. The reason
is that we have used the simplest possible all-to-all connected
architecture with only one hidden layer. Below, we will introduce more
advanced neural network features and show how to increase the
performance.</p>
<p>Before doing so, we briefly introduce other important measures used to
characterize the performance of specifically <strong>binary-classification</strong>
models in statistics are: <em>precision</em>, <em>specificity</em> and <em>recall</em>. In
the language of true (false) positives (negatives) the precision is
defined as</p>
<div class="math notranslate nohighlight">
\[\text{precision} = \frac{\text{true positives}}{\text{true positives}+\text{false positives}}.\]</div>
<p>Recall (also referred to as sensitivity) is defined as</p>
<div class="math notranslate nohighlight">
\[\text{recall} = \frac{\text{true positives}}{\text{true positives}+\text{false negatives}}.\]</div>
<p>While recall can be interpreted as true positive rate as it represents
the ratio between actual positives and outcomes identified as positive,
the specificity is an analogous measures for negatives</p>
<div class="math notranslate nohighlight">
\[\text{specificity} = \frac{\text{true negatives}}{\text{true negatives}+\text{false positives}}.\]</div>
<p>Note, however, that these measures can be misleading, in particular when
dealing with very unbalanced data sets.</p>
<hr class="docutils" />
<dl class="footnote brackets">
<dt class="label" id="id3"><span class="brackets"><a class="fn-backref" href="#id1">3</a></span></dt>
<dd><p>Backpropagation is actually a special case of a set of techniques
known as <em>automatic differentiation</em> (AD). AD makes use of the fact
that any computer program can be composed of elementary operations
(addition, subtraction, multiplication, division) and elementary
functions (<span class="math notranslate nohighlight">\(\sin, \exp, \dots\)</span>). By repeated application of the
chain rule, derivatives of arbitrary order can be computed
automatically.</p>
</dd>
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id2">4</a></span></dt>
<dd><p>Most ML packages have some type of ’train’ function built in, so
no need to worry about implementing back-propagation by hand. All
that is needed here is to call the ’train’ function</p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs/supervised_learning_w_NNs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="ml_intro_neural.html" title="previous page">Computational neurons</a>
    <a class='right-next' id="next-link" href="ml_convolutional.html" title="next page">Regularization</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Machine Learning for Science Team<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>